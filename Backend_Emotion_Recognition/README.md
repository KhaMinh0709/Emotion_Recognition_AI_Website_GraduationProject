# Backend Emotion Recognition API

This project implements a FastAPI-based backend service for emotion recognition using both facial and audio inputs.

## Project Structure

```
BACKEND_EMOTION_RECOGNITION/
‚îÇ
‚îú‚îÄ‚îÄ app/                         # Main application package
‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # FastAPI application entry point
‚îÇ   ‚îú‚îÄ‚îÄ api/                    # API route definitions
‚îÇ   ‚îú‚îÄ‚îÄ core/                   # Core configuration
‚îÇ   ‚îú‚îÄ‚îÄ models/                 # ML/DL model implementations
‚îÇ   ‚îú‚îÄ‚îÄ services/               # Business logic layer
‚îÇ   ‚îú‚îÄ‚îÄ schemas/               # Pydantic models
‚îÇ   ‚îú‚îÄ‚îÄ utils/                 # Utility functions
‚îÇ   ‚îî‚îÄ‚îÄ static/                # Static file storage
‚îÇ
‚îú‚îÄ‚îÄ models/                    # Trained model files
‚îî‚îÄ‚îÄ requirements.txt          # Python dependencies
```

## Setup

1. Create a virtual environment:
```bash
cd Backend_Emotion_Recognition
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```
```bash
.\venv\Scripts\Activate.ps1
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Place your trained models in the `models/` directory:
- `face_model.h5` for facial emotion recognition
- `audio_model.pth` for audio emotion recognition
- `fusion_model.pth` for multimodal fusion

## Running the Application

Start the server:
```bash
uvicorn app.main:app --reload
```

The API will be available at `http://localhost:8000`

## API Endpoints

### Face Emotion Recognition
- POST `/face/upload`: Upload face image
- POST `/face/predict`: Predict emotion from face image

### Audio Emotion Recognition
- POST `/audio/upload`: Upload audio file
- POST `/audio/predict`: Predict emotion from audio

### Multimodal Fusion
- POST `/fusion/predict`: Predict emotion using both face and audio inputs

## Environment Variables

Create a `.env` file in the root directory with the following variables:
```
DEBUG=True
MAX_UPLOAD_SIZE=10485760
```
## Api documents
Swagger UI (giao di·ªán t∆∞∆°ng t√°c, ‚ÄúTry it out‚Äù):
http://localhost:8000/docs

ReDoc (t√†i li·ªáu ƒë·ªçc):
http://localhost:8000/redoc

Raw OpenAPI JSON (n·∫øu c·∫ßn):
http://localhost:8000/openapi.json

##üöÄ H∆Ø·ªöNG D·∫™N C√ÄI FFMPEG:
B∆∞·ªõc 1: M·ªü PowerShell as Administrator
Nh·∫•n Windows + X
Ch·ªçn "Windows PowerShell (Admin)" ho·∫∑c "Terminal (Admin)"
B∆∞·ªõc 2: Ki·ªÉm tra c√≥ Chocolatey ch∆∞a
G√µ l·ªánh n√†y:
```bash
choco
```
N·∫øu c√≥, Chocolatey s·∫Ω hi·ªÉn th·ªã logo v√† th√¥ng tin. N·∫øu kh√¥ng, c√†i Chocolatey:
```bash
B∆∞·ªõc 3: C√†i Chocolatey (n·∫øu ch∆∞a c√≥)
Copy v√† paste l·ªánh n√†y v√†o PowerShell:
```bash
Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))
```bash
B∆∞·ªõc 4: C√†i ffmpeg
G√µ l·ªánh n√†y:
```bash
choco install ffmpeg
```bash
B∆∞·ªõc 5: Ki·ªÉm tra l·∫°i
G√µ l·ªánh n√†y:
```bash
ffmpeg -version
```bash
N·∫øu c√≥, ffmpeg ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t th√†nh c√¥ng.

### CLIENT
  ‚Üì File audio (MP3/WebM/WAV/OGG...) - b·∫•t k·ª≥ format
  
BACKEND ENDPOINT (/audio/predict)
  ‚Üì UploadFile object
  
AudioService.predict()
  ‚Üì bytes c·ªßa file audio
  
_convert_to_wav()
  ‚Üì bytes c·ªßa WAV file (chu·∫©n h√≥a)
  
soundfile.read()
  ‚Üì numpy array (n_samples,) + sample_rate
  
_get_predict_feat_from_array()
  ‚Üì numpy array (1, 2376, 1) - features
  
CNN MODEL
  ‚Üì numpy array (1, 7) - x√°c su·∫•t 7 emotions
  
Encoder.inverse_transform()
  ‚Üì emotion name + confidence + all_emotions
  
RESPONSE
  ‚Üì JSON: {emotion, confidence, all_emotions}
  
CLIENT
  ‚úÖ Hi·ªÉn th·ªã k·∫øt qu·∫£